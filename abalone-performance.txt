5(a)
(A) Base-DT-max_depth=8
(B) Confusion Matrix:

[[127  48 156]
 [ 38 237  50]
 [138  66 185]]

(C) (D) Classification metrics:

              precision    recall  f1-score   support

           F       0.42      0.38      0.40       331
           I       0.68      0.73      0.70       325
           M       0.47      0.48      0.47       389

    accuracy                           0.53      1045
   macro avg       0.52      0.53      0.53      1045
weighted avg       0.52      0.53      0.52      1045

6(a)
(A) Accuracy: Mean = 0.5226794258373205, Variance =7.838648382591912e-06
(B) Macro Average F1: Mean = 0.522957643445253, Variance = 6.545631305464045e-06
(C) Weighted Average F1: Mean = 0.5192913922115819 , Variance = 6.5213762936747806e-06
5(b)
(A) Top-DT-criterion=entropy-max_depth=10-min_samples_split=200
(B) Confusion Matrix:

[[128  45 158]
 [ 32 245  48]
 [132  67 190]]

(C) (D) Classification metrics:

              precision    recall  f1-score   support

           F       0.44      0.39      0.41       331
           I       0.69      0.75      0.72       325
           M       0.48      0.49      0.48       389

    accuracy                           0.54      1045
   macro avg       0.53      0.54      0.54      1045
weighted avg       0.53      0.54      0.53      1045

6(b)
(A) Accuracy: Mean = 0.538755980861244, Variance =0.0
(B) Macro Average F1: Mean = 0.5378221447345541, Variance = 0.0
(C) Weighted Average F1: Mean = 0.5338018874665538 , Variance = 0.0
5(c)
(A) Base-MLP-hidden_layer_sizes=(100,100)-activation=logistic-solver=sdg
(B) Confusion Matrix:

[[  6  57 268]
 [  2 224  99]
 [  9  74 306]]

(C) (D) Classification metrics:

              precision    recall  f1-score   support

           F       0.35      0.02      0.03       331
           I       0.63      0.69      0.66       325
           M       0.45      0.79      0.58       389

    accuracy                           0.51      1045
   macro avg       0.48      0.50      0.42      1045
weighted avg       0.48      0.51      0.43      1045

6(c)
(A) Accuracy: Mean = 0.5150239234449762, Variance =1.6116847141778418e-06
(B) Macro Average F1: Mean = 0.41587244950146074, Variance = 1.3713791995248744e-05
(C) Weighted Average F1: Mean = 0.4237041046743039 , Variance = 1.1338059329233023e-05
5(d)
(A) Top-MLP-activation=logistic-hidden_layer_sizes=(10, 10, 10)-solver=adam
(B) Confusion Matrix:

[[ 79  39 213]
 [  1 251  73]
 [ 93  72 224]]

(C) (D) Classification metrics:

              precision    recall  f1-score   support

           F       0.46      0.24      0.31       331
           I       0.69      0.77      0.73       325
           M       0.44      0.58      0.50       389

    accuracy                           0.53      1045
   macro avg       0.53      0.53      0.51      1045
weighted avg       0.52      0.53      0.51      1045

6(d)
(A) Accuracy: Mean = 0.5423923444976078, Variance =4.153751058812746e-05
(B) Macro Average F1: Mean = 0.4898876608023193, Variance = 0.001468730557054108
(C) Weighted Average F1: Mean = 0.4916912319400768 , Variance = 0.0011613901249502333
